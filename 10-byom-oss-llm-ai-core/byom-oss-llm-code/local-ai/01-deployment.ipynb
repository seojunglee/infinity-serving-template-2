{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7dea42f",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This notebook illustrates and automates the Continuous Deployment process for bringing the popular open-source large language models service [LocalAI](https://localai.io/) into SAP AI Core. Running LLaMa 3, Phi3, Mistral, Mixtral, LlaVA, Gemma etc. in SAP AI Core through BYOM(Bring Your Own Model) approach. <br/>\n",
    "\n",
    "### Prerequisites\n",
    "Before running this notebook, please assure you have perform the [Prerequisites](../../README.md)<br/><br/>\n",
    "\n",
    "If the configuration of local-ai scenario is created through SAP AI Launchpad instead of running [00-init-config.ipynb](../00-init-config.ipynb), please manually update the configuration_id in [env.json](env.json)\n",
    "```json\n",
    "{\n",
    "    \"configuration_id\": \"<YOUR_CONFIGURATION_ID_OF_LOCAL_AI_SCENARIO>\",\n",
    "    \"deployment_id\": \"<WILL_BE_UPDATED_BY_THIS_NOTEBOOK>\"\n",
    "}\n",
    "```\n",
    " \n",
    "### The high-level flow of this Continuous Deployment process:\n",
    "- Build a custom LocalAI docker image adapted for SAP AI Core<br/>\n",
    "- Push the docker image to docker hub<br/>\n",
    "- Connect to SAP AI Core via SDK<br/>\n",
    "- Create a deployment<br/>\n",
    "- Check the status and logs of the deployment<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3925c841",
   "metadata": {},
   "source": [
    "#### 1.Build a custom LocalAI docker image adapted for SAP AI Core\n",
    "Please refer to [Dockerfile](Dockerfile) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dfb1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# 0.Login to docker hub\n",
    "docker login -u <YOUR_DOCKER_USER> -p <YOUR_DOCKER_ACCESS_TOKEN>\n",
    "\n",
    "# 1.Build the docker image\n",
    "docker build \\\n",
    "\t\t--platform=linux/amd64 \\\n",
    "\t\t--build-arg IMAGE_TYPE=core \\\n",
    "\t\t--build-arg GO_TAGS= \\\n",
    "\t\t--build-arg BUILD_TYPE=cublas \\\n",
    "\t\t-t docker.io/<YOUR_DOCKER_USER>/local-ai:ai-core ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081a7cf",
   "metadata": {},
   "source": [
    "#### 2.Push the docker image to docker hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa521107",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# 2.Push the docker image to docker hub to be used by deployment in SAP AI Core\n",
    "docker push docker.io/<YOUR_DOCKER_USER>/local-ai:ai-core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9332238f",
   "metadata": {},
   "source": [
    "#### 3.Initiate an SAP AI Core SDK client\n",
    "- resource_group loaded from [../config.json](../config.json)\n",
    "- ai_core_sk(service key) loaded from [../config.json](../config.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90f1e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, time, datetime\n",
    "from datetime import datetime\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12912738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource group:  oss-llm\n"
     ]
    }
   ],
   "source": [
    "# load the configuration from ../config.json \n",
    "with open(\"../config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "resource_group = config.get(\"resource_group\", \"default\")\n",
    "print( \"resource group: \", resource_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7654d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate an AI Core SDK client with the information of service key\n",
    "ai_core_sk = config[\"ai_core_service_key\"]\n",
    "base_url = ai_core_sk.get(\"serviceurls\").get(\"AI_API_URL\") + \"/v2/lm\"\n",
    "client = AICoreV2Client(base_url=ai_core_sk.get(\"serviceurls\").get(\"AI_API_URL\")+\"/v2\",\n",
    "                        auth_url=ai_core_sk.get(\"url\")+\"/oauth/token\",\n",
    "                        client_id=ai_core_sk.get(\"clientid\"),\n",
    "                        client_secret=ai_core_sk.get(\"clientsecret\"),\n",
    "                        resource_group=resource_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c5b6e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the http header which will be used later through request.\n",
    "token = client.rest_client.get_token()\n",
    "headers = {\n",
    "    \"Authorization\": token,\n",
    "    \"ai-resource-group\": resource_group,\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d440ee60",
   "metadata": {},
   "source": [
    "#### 4.Create a deployment for LocalAI scenario\n",
    "To create a deployment in SAP AI Core, it requires the corresponding resource_group and configuration_id\n",
    "- resource_group loaded from [../config.json](../config.json)\n",
    "- configuration_id of  loaded from [env.json](env.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "788f8134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuration id: 6303f3ad-6204-4b31-94fe-28edb29c0220\n"
     ]
    }
   ],
   "source": [
    "# resource_group: The target resource group to create the deployment\n",
    "# configuration_id: The target configuration to create the deployment, which is created in ../00-init-config.ipynb \n",
    "with open(\"./env.json\") as f:\n",
    "    env = json.load(f)\n",
    "\n",
    "configuration_id = env[\"configuration_id\"]\n",
    "print(\"configuration id:\", configuration_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f8856",
   "metadata": {},
   "source": [
    "**Helper function**\n",
    "- get the current UTC time in yyyy-mm-dd hh:mm:ss format, to be used to filter deployments logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2c097ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get the current time in UTC, used to filter deployments logs\n",
    "def get_current_time():  \n",
    "    current_time = datetime.utcnow()\n",
    "    # Format current time in the desired format\n",
    "    formatted_time = current_time.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    return formatted_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff6ef20",
   "metadata": {},
   "source": [
    "**Helper function**\n",
    "- Write back the configuration value back to configuration json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9df6fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write back the configuration value back to configuration json file\n",
    "def update_json_file(file_path, key, value):\n",
    "    # Load the JSON configuration file\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = json.load(file)\n",
    "\n",
    "    # Update the value\n",
    "    config[key] = value\n",
    "\n",
    "    # Write the updated configuration back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(config, file, indent=4)\n",
    "        print(f\"{file_path} updated. {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e20a1a",
   "metadata": {},
   "source": [
    "**Create a deployment for LocalAI in SAP AI Core**\n",
    "- configuration_id\n",
    "- resource_group\n",
    "<br/><br/>\n",
    "The created deployment id will be written back to [env.json](env.json), which will be used in\n",
    "- [02-local-ai.ipynb](02-local-ai.ipynb) and [03-local-ai-llava.ipynb](03-local-ai-llava.ipynb) to test the inference of open-source llms with Ollama in SAP AI Core\n",
    "- [04-cleanup.ipynb](04-cleanup.ipynb) to stop the deployment and clean up the resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab19296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating deployment.\n",
      "env.json updated. deployment_id: d09391ae26f8c16d\n",
      "Deployment Result:\n",
      " {'id': 'd09391ae26f8c16d', 'message': 'Deployment scheduled.', 'deployment_url': '', 'status': <Status.UNKNOWN: 'UNKNOWN'>, 'ttl': None}\n"
     ]
    }
   ],
   "source": [
    "# Create a Deployment in SAP AI Core\n",
    "print(\"Creating deployment.\")\n",
    "response = client.deployment.create(\n",
    "    configuration_id=configuration_id,\n",
    "    resource_group=resource_group\n",
    ")\n",
    "\n",
    "# last_check_time will be used to check the deployment status continuously afterwards\n",
    "# set initial last_check_time right after creating deployment\n",
    "last_check_time = get_current_time()\n",
    "deployment_start_time = datetime.now()\n",
    "\n",
    "deployment_id = response.id\n",
    "status = response.status\n",
    "update_json_file(\"env.json\", \"deployment_id\", deployment_id)\n",
    "print(\"Deployment Result:\\n\", response.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc074976",
   "metadata": {},
   "source": [
    "#### 5.Check the status and logs of the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcd4c564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.Checking deployment status.\n",
      "...... Deployment Status at 2024-03-26T12:34:13.226883Z......\n",
      "Deployment status: UNKNOWN\n",
      "Deployment logs: {\n",
      "  \"error\": {\n",
      "    \"code\": \"05011000\",\n",
      "    \"message\": \"DeploymentNotFoundError: Deployment d09391ae26f8c16d not found.\",\n",
      "    \"target\": \"/api/v4alpha/deployments/d09391ae26f8c16d/logs\"\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:34:35.967429Z......\n",
      "Deployment status: UNKNOWN\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:34:58.806662Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:35:21.946680Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:35:46.320392Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:36:15.397281Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:36:44.688405Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:37:07.793550Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:37:33.128028Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:37:55.809367Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:38:22.479139Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": [\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"@@@@@\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.154618501+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"Skipping rebuild\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.154638290+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"@@@@@\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.154641866+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"If you are experiencing issues with the pre-compiled builds, try setting REBUILD=true\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.154644966+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"If you are still experiencing issues with the build, try setting CMAKE_ARGS and disable the instructions set as needed:\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.154647827+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"CMAKE_ARGS=\\\"-DLLAMA_F16C=OFF -DLLAMA_AVX512=OFF -DLLAMA_AVX2=OFF -DLLAMA_FMA=OFF\\\"\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.154651165+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"see the documentation at: https://localai.io/basics/build/index.html\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.154654264+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"Note: See also https://github.com/go-skynet/LocalAI/issues/288\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.154657125+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"@@@@@\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.154659986+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"CPU info:\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.154662847+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"model name\\t: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.154665708+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"flags\\t\\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves ida arat pku ospke avx512_vnni\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.155987977+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"CPU:    AVX    found OK\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.177324771+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"CPU:    AVX2   found OK\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.178198575+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"CPU:    AVX512 found OK\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.179085969+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"@@@@@\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.179094076+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \" * Starting nginx nginx\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.202994346+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"   ...done.\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.239068984+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"service nginx started\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.239197969+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[32mINF\\u001b[0m Starting LocalAI using 4 threads, with models path: /build/models\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.254064798+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[32mINF\\u001b[0m LocalAI version: ead61bf (ead61bf9d5b6024d2a6a971bbdfd612c8e059aa7)\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.254077911+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[32mINF\\u001b[0m Preloading models from /build/models\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:12.254376888+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[33mDBG\\u001b[0m Checking \\\"mistral-7b-openorca.Q6_K.gguf\\\" exists and matches SHA\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:13.699843645+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[32mINF\\u001b[0m Downloading \\\"https://huggingface.co/TheBloke/Mistral-7B-OpenOrca-GGUF/resolve/main/mistral-7b-openorca.Q6_K.gguf\\\"\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:13.699866771+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[32mINF\\u001b[0m Downloading /build/models/mistral-7b-openorca.Q6_K.gguf.partial: 467.0 MiB/5.5 GiB (8.24%) ETA: 55.66831764s\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:17.254658460+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[32mINF\\u001b[0m Downloading /build/models/mistral-7b-openorca.Q6_K.gguf.partial: 1.3 GiB/5.5 GiB (22.71%) ETA: 34.034746131s\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:22.254786014+00:00\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:38:45.122639Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": [\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[32mINF\\u001b[0m Downloading /build/models/mistral-7b-openorca.Q6_K.gguf.partial: 2.0 GiB/5.5 GiB (36.22%) ETA: 26.414162008s\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:27.254835367+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[32mINF\\u001b[0m Downloading /build/models/mistral-7b-openorca.Q6_K.gguf.partial: 2.9 GiB/5.5 GiB (51.82%) ETA: 18.59398336s\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:32.254865169+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[32mINF\\u001b[0m Downloading /build/models/mistral-7b-openorca.Q6_K.gguf.partial: 3.6 GiB/5.5 GiB (65.93%) ETA: 12.920863623s\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:37.254976272+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[32mINF\\u001b[0m Downloading /build/models/mistral-7b-openorca.Q6_K.gguf.partial: 4.3 GiB/5.5 GiB (77.84%) ETA: 8.542177913s\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:42.255097627+00:00\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:39:11.949368Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": [\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[32mINF\\u001b[0m Downloading /build/models/mistral-7b-openorca.Q6_K.gguf.partial: 5.2 GiB/5.5 GiB (93.63%) ETA: 2.379585666s\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:47.256129980+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[32mINF\\u001b[0m File \\\"/build/models/mistral-7b-openorca.Q6_K.gguf\\\" downloaded and verified\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:49.507343530+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[33mDBG\\u001b[0m Prompt template \\\"chatml\\\" written\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:49.507424354+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[33mDBG\\u001b[0m Prompt template \\\"chatml-block\\\" written\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:49.507481098+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[33mDBG\\u001b[0m Prompt template \\\"completion\\\" written\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:49.507536172+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[33mDBG\\u001b[0m Written config file /build/models/mistral.yaml\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:49.507858037+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[33mDBG\\u001b[0m Extracting backend assets files to /tmp/localai/backend_data\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:51.801756858+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[32mINF\\u001b[0m core/startup process completed!\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:51.801781177+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\\u001b[90m12:38PM\\u001b[0m \\u001b[33mDBG\\u001b[0m No uploadedFiles file found at /tmp/localai/upload/uploadedFiles.json\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:51.802011013+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:51.802410840+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \" \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:51.802422523+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \" \\u2502                   Fiber v2.50.0                   \\u2502 \",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:51.802425861+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \" \\u2502               http://127.0.0.1:8080               \\u2502 \",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:51.802428007+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \" \\u2502       (bound on host 0.0.0.0 and port 8080)       \\u2502 \",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:51.802430152+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \" \\u2502                                                   \\u2502 \",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:51.802432298+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \" \\u2502 Handlers ........... 109  Processes ........... 1 \\u2502 \",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:51.802434682+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \" \\u2502 Prefork ....... Disabled  PID ................ 28 \\u2502 \",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:51.802444934+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \" \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:51.802447319+00:00\"\n",
      "      },\n",
      "      {\n",
      "        \"container\": \"kserve-container\",\n",
      "        \"msg\": \"\",\n",
      "        \"pod\": \"d09391ae26f8c16d-predictor-default-00001-deployment-5597bbxz5tf\",\n",
      "        \"timestamp\": \"2024-03-26T12:38:51.802449464+00:00\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:39:38.691255Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:40:02.019520Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:40:31.406217Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:40:53.901001Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:41:16.624620Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:41:41.666196Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:42:04.694332Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:42:32.240696Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:42:57.937958Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:43:23.313380Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:43:49.656996Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:44:12.239839Z......\n",
      "Deployment status: PENDING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "...... Deployment Status at 2024-03-26T12:44:39.308620Z......\n",
      "Deployment status: RUNNING\n",
      "Deployment logs: {\n",
      "  \"data\": {\n",
      "    \"result\": []\n",
      "  }\n",
      "}\n",
      "\n",
      "Deployment is up and running now!\n",
      "Deployment duration: 0:00:11.053341 mins\n"
     ]
    }
   ],
   "source": [
    "print(\"5.Checking deployment status.\")\n",
    "deployment_url = f\"{base_url}/deployments/{deployment_id}\"\n",
    "deployment_log_url = f\"{deployment_url}/logs?start=\"\n",
    "interval_s = 20\n",
    "\n",
    "while status != \"RUNNING\" and status != \"DEAD\":\n",
    "    current_time = get_current_time()\n",
    "    #check deployment status\n",
    "    response = requests.get(url=deployment_url, headers=headers)\n",
    "    resp = response.json()\n",
    "    \n",
    "    status = resp['status']\n",
    "    print(f'...... Deployment Status at {current_time}......', flush=False)\n",
    "    print(f\"Deployment status: {status}\")\n",
    "\n",
    "    #retrieve deployment logs\n",
    "    response_log = requests.get(url=f\"{deployment_log_url}{last_check_time}\", headers=headers)\n",
    "    last_check_time = current_time\n",
    "    print(f\"Deployment logs: {response_log.text}\")\n",
    "\n",
    "    # Sleep for 60 secs to avoid overwhelming the API with requests\n",
    "    time.sleep(interval_s)\n",
    "\n",
    "deployment_end_time = datetime.now()\n",
    "duration_in_min = (deployment_end_time - deployment_start_time) / 60\n",
    "\n",
    "if status == \"RUNNING\":\n",
    "    print(\"Deployment is up and running now!\")\n",
    "else:\n",
    "    print(f\"Deployment {deployment_id} failed!\")   \n",
    "\n",
    "print(f\"Deployment duration: {duration_in_min} mins\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
