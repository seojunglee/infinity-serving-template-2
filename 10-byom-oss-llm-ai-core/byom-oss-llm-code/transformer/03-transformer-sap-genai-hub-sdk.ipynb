{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a5a74d",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In this notebook, we will test out [Microsoft's Phi-3-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct) with the [custom inference server with hugging face transformers library](app/server.py) within SAP AI Core through [SAP Generative AI Hub SDK](https://pypi.org/project/generative-ai-hub-sdk/), which can significantly simplify the integration of self-hosted open-source LLMs in SAP AI Core with your own application, and provides the same interface as proprietary LLMs in SAP Generative AI Hub.<br/><br/>\n",
    "\n",
    "In addition, you can also run another transformer-based open-source LLM on [Hugging Face](https://huggingface.co), like [microsoft/Phi-3-medium-128k-instruct](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct) etc.\n",
    "\n",
    "### Prerequisites\n",
    "Before running this notebook, please assure you have performed the [Prerequisites](../../README.md) and [01-deployment.ipynb](01-deployment.ipynb). As a result, a deployment of transformer scenario is running in SAP AI Core. <br/><br/>\n",
    "\n",
    "If the configuration and deployment are created through SAP AI Launchpad, please manually update the configuration_id and deployment_id in [env.json](env.json)\n",
    "```json\n",
    "{\n",
    "    \"configuration_id\": \"<YOUR_CONFIGURATION_ID_OF_TRANSFORMER_SCENARIO>\",\n",
    "    \"deployment_id\": \"<YOUR_DEPLOYMENT_ID_BASED_ON_CONFIG_ABOVE>\"\n",
    "}\n",
    "```\n",
    "\n",
    "### The high-level flow:\n",
    "- Load configurations info\n",
    "- Connect to SAP AI Core via its SDK\n",
    "- Check the status and logs of the deployment\n",
    "- Register the byom-open-source-llm scenario as a foundation model scenario via SAP Generative AI Hub SDK\n",
    "- Inference the model through **SAP Generative AI Hub SDK**\n",
    "    - Option 1: Proxy with OpenAI-like interface\n",
    "    - Option 2: Proxy with Langchain-like interface\n",
    "    - Option 3: Proxy with Langchain-like interface, together with Langchain components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c55bd7b",
   "metadata": {},
   "source": [
    "#### 1.Load config info \n",
    "- resource_group loaded from [config.json](../config.json)\n",
    "- deployment_id(created in 01-deployment.ipynb) loaded [env.json](env.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee26b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please replace the configurations below.\n",
    "# config_id: The target configuration to create the deployment. Please create the configuration first.\n",
    "with open(\"../config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "with open(\"./env.json\") as f:\n",
    "    env = json.load(f)\n",
    "\n",
    "deployment_id = env[\"deployment_id\"]\n",
    "resource_group = config.get(\"resource_group\", \"default\")\n",
    "print(\"deployment id: \", deployment_id, \" resource group: \", resource_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd694c3",
   "metadata": {},
   "source": [
    "#### 2.Initiate connection to SAP AI Core "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4cc0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate an AI Core SDK client with the information of service key\n",
    "ai_core_sk = config[\"ai_core_service_key\"]\n",
    "base_url = ai_core_sk.get(\"serviceurls\").get(\"AI_API_URL\") + \"/v2/lm\"\n",
    "ai_core_client = AICoreV2Client(base_url=ai_core_sk.get(\"serviceurls\").get(\"AI_API_URL\")+\"/v2\",\n",
    "                        auth_url=ai_core_sk.get(\"url\")+\"/oauth/token\",\n",
    "                        client_id=ai_core_sk.get(\"clientid\"),\n",
    "                        client_secret=ai_core_sk.get(\"clientsecret\"),\n",
    "                        resource_group=resource_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = ai_core_client.rest_client.get_token()\n",
    "headers = {\n",
    "        \"Authorization\": token,\n",
    "        'ai-resource-group': resource_group,\n",
    "        \"Content-Type\": \"application/json\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7b416",
   "metadata": {},
   "source": [
    "#### 3.Check the deployment status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46cf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check deployment status before inference request\n",
    "deployment_url = f\"{base_url}/deployments/{deployment_id}\"\n",
    "response = requests.get(url=deployment_url, headers=headers)\n",
    "resp = response.json()    \n",
    "status = resp['status']\n",
    "\n",
    "deployment_log_url = f\"{base_url}/deployments/{deployment_id}/logs\"\n",
    "if status == \"RUNNING\":\n",
    "        print(f\"Deployment-{deployment_id} is running. Ready for inference request\")\n",
    "else:\n",
    "        print(f\"Deployment-{deployment_id} status: {status}. Not yet ready for inference request\")\n",
    "        #retrieve deployment logs\n",
    "        #{{apiurl}}/v2/lm/deployments/{{deploymentid}}/logs.\n",
    "\n",
    "        response = requests.get(deployment_log_url, headers=headers)\n",
    "        print('Deployment Logs:\\n', response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b4fcb",
   "metadata": {},
   "source": [
    "#### 4.Register the scenario as a foundation model scenario for SAP Generative AI Hub SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4002137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.gen_ai_hub_proxy import GenAIHubProxyClient\n",
    "\n",
    "GenAIHubProxyClient.add_foundation_model_scenario(\n",
    "    scenario_id=\"byom-transformer-server\",\n",
    "    config_names=\"transformer*\",\n",
    "    prediction_url_suffix=\"/v1/chat/completions\",\n",
    ")\n",
    "\n",
    "proxy_client = GenAIHubProxyClient(ai_core_client = ai_core_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d42754",
   "metadata": {},
   "source": [
    "Set the target model to be used with SAP Generative AI Hub. It must be identical as the modelName setup in the configuration in SAP AI Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86047d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"microsoft/Phi-3-vision-128k-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a7d13c",
   "metadata": {},
   "source": [
    "#### 5. Basic Samples about Three Options of using SAP Generative AI Hub SDK in BYOM Open-Source LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848db40",
   "metadata": {},
   "source": [
    "##### 5.1 Option 1-Proxy with OpenAI-like interface\n",
    "Now let's test its OpenAI compatible API for Chat Completion via Proxy with OpenAI-like interface in SAP Generative AI Hub SDK, which is the exact API interface of Chat Completion of GPT-3.5/4 in SAP Generative AI Hub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb1b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Proxy with OpenAI-like interface\n",
    "from gen_ai_hub.proxy.native.openai import OpenAI\n",
    "\n",
    "openai = OpenAI(proxy_client=proxy_client)\n",
    "messages = [{\"role\": \"user\", \"content\": \"Tell me a joke\"}]\n",
    "# kwargs = dict(deployment_id='xxxxxxx', model=model,messages = messages)\n",
    "result = openai.chat.completions.create(\n",
    "    # **kwargs\n",
    "    deployment_id=deployment_id,\n",
    "    model=model,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(\"Option 1: Proxy with OpenAI-like interface\\n\", result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df95b2",
   "metadata": {},
   "source": [
    "##### 5.2 Option 2-Proxy with Langchain-like interface\n",
    "Now let's test its OpenAI compatible API for Chat Completion via Proxy with Langchain-like interface in SAP Generative AI Hub SDK, which is the exact API interface of Chat Completion of GPT-3.5/4 in SAP Generative AI Hub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Proxy with Langchain-like interface\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content=\"Tell me a joke\")]\n",
    "llm = ChatOpenAI(\n",
    "    proxy_client=proxy_client,\n",
    "    deployment_id=deployment_id,\n",
    "    model_name=model\n",
    ")\n",
    "completion = llm.invoke(messages)\n",
    "print(\"Option 2: Proxy with Langchain-like interface\\n\", completion.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7aae2c",
   "metadata": {},
   "source": [
    "##### 5.3 Option 3-Proxy with Langchain-like interface, together with Langchain components\n",
    "Now let's test its OpenAI compatible API for Chat Completion via Proxy with  Langchain-like interface, together with Langchain components in SAP Generative AI Hub SDK, which is the exact API interface of Chat Completion of GPT-3.5/4 in SAP Generative AI Hub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a61fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Proxy with Langchain-like interface, together with Langchain components\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    proxy_client=proxy_client,\n",
    "    deployment_id=deployment_id,\n",
    "    model_name=model,\n",
    "    temperature=0.5,\n",
    "    max_tokens=400,\n",
    "    # model_kwargs={\n",
    "    #     \"frequency_penalty\": -2, \"presence_penalty\": -1\n",
    "    # }\n",
    ")\n",
    "\n",
    "template = \"Tell me a joke about {topic}\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"topic\"])\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "completion = llm_chain.invoke({\"topic\": \"Generative AI\"})\n",
    "\n",
    "print(\"Option 3: Proxy with Langchain-like interface, together with Langchain components\\n\",completion.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f2065",
   "metadata": {},
   "source": [
    "##### 5.4 Vision Sample#4: Public Facilities Issue Spotter for [Citizen Reporting use case](https://github.com/SAP-samples/btp-generative-ai-hub-use-cases/tree/main/01-social-media-citizen-reporting) (e.g. a dirty street)\n",
    "\n",
    "In next sample, we'll ask [Microsoft's Phi-3-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3-small-128k-instruct) model to be an Assistant of Public Facilities Issue Spotter for city council.\n",
    "Responsible for analyzing images reported by citizens through a mobile app to identify issues related to public facilities. <br/>\n",
    "Here are the tasks: <br/>\n",
    "\n",
    "- 1.Analyze images reported by citizens through a mobile app to identify issues related to public facilities. If no issue identified, go to step 5, otherwise continue with next steps\n",
    "- 2.Extract photographic date and location information from images for accurate documentation.\n",
    "- 3.Categorize identified issues based on predefined categories (e.g., infrastructure damage, cleanliness, safety hazards).\n",
    "- 4.Assess the severity and priority of identified issues to determine appropriate action plans.\n",
    "- 5.Output with JSON schema in triple quote as below:\n",
    "\n",
    "```json\n",
    "{ \"issue_identified\": \"{{true or false}}\",\n",
    "#below section only output when there is an issue identified\n",
    "\"title\": \"{{A title about the issue less than 100 characters}}\",\n",
    "\"description\": \"{{A short description about the issue less than 300 characters}}\",\n",
    "\"photo_date\": \"{{Extracted photographic date from its metadata in yyyy-mm-dd:hh:mm:ss format}}\",\n",
    "\"longitude\": \"{{Extracted the longitude of photographic location from its metadata. Output -1 if fails to extract location info from image}}\",\n",
    "\"latitude\": \"{{Extracted the latitude of photographic location from its metadata. Output -1 if fails to extract location info from image}}\",\n",
    "\"category\": \"{{Identified category: 01-Infrastructure Damage, 02-Cleanliness, 03-Safety Hazards, 04-Duplicated}}\",\n",
    "\"priority\": \"{{Identified priority: 01-Very High, 02-High, 03-Medium, 04-Low}}\",\n",
    "\"suggested_action\": \"{{01-Immediate Attendance, 02-Schedule Inspection, 03-Schedule Service, 04-Refer to similar issue}}\"\n",
    "}\n",
    "```\n",
    "\n",
    "<br/>\n",
    "We'll inference the vision model through SAP Generative AI Hub.<br/>\n",
    "Firstly, let's have a look at the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "image_url = \"https://raw.githubusercontent.com/SAP-samples/btp-generative-ai-hub-use-cases/main/10-byom-oss-llm-ai-core/resources/11-dirty-street.jpg\"\n",
    "# Display the image\n",
    "display(Image(url=image_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f61fb",
   "metadata": {},
   "source": [
    "Prepare the request as OpenAI-like chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deced2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_msg = 'You are a helpful Assistant of Public Facilities Issue Spotter for city council.\\\n",
    "Responsible for analyzing images reported by citizens through a mobile app to identify issues related to public facilities. \\\n",
    "Here are your tasks:\\\n",
    "1.Analyze images reported by citizens through a mobile app to identify issues related to public facilities. \\\n",
    "If no issue identified, go to step 5, otherwise continue with next steps \\\n",
    "2.Extract photographic date and location information from images for accurate documentation. \\\n",
    "3.Categorize identified issues based on predefined categories (e.g., infrastructure damage, cleanliness, safety hazards).\\\n",
    "4.Assess the severity and priority of identified issues to determine appropriate action plans. \\\n",
    "5.Output with JSON schema in triple quote as below:\\\n",
    "\"\"\" \\\n",
    "{ \"issue_identified\": \"{{true or false}}\", \\\n",
    "#below section only output when there is an issue identified\\\n",
    "\"title\": \"{{A short title about the issue}}\", \\\n",
    "\"description\": \"{{A detail description about the issue}}\", \\\n",
    "\"photo_date\": \"{{Extracted photographic date from its metadata in yyyy-mm-dd:hh:mm:ss format. Leave it blank if no metadata found in it.}}\", \\\n",
    "\"longitude\": \"{{Extracted longitude of photographic location from its metadata. Do not make up any number. Output -1 if fails to extract location info from image}}\",\\\n",
    "\"latitude\": \"{{Extracted latitude of photographic location from its metadata. Do not make up any number. Output -1 if fails to extract location info from image}}\",\\\n",
    "\"category\": \"{{Identified category: 01-Infrastructure Damage, 02-Cleanliness, 03-Safety Hazards, 04-Duplicated}}\",\\\n",
    "\"priority\": \"{{Suggested Priority: 01-Very High, 02-High, 03-Medium, 04-Low}}\",\\\n",
    "\"suggested_action\": \"{{01-Immediate Attendance, 02-Schedule Inspection, 03-Schedule Service, 04-Refer to similar issue }}\"\\\n",
    "} \\\n",
    "\"\"\"\\\n",
    "'\n",
    "\n",
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": user_msg},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url\n",
    "                    },\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "#JSON Mode\n",
    "response_format={\"type\": \"json_object\"} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeabc963",
   "metadata": {},
   "source": [
    "Inference the model through OpenAI-like interfaces through native OpenAI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e090a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Proxy with OpenAI-like interface\n",
    "from gen_ai_hub.proxy.native.openai import OpenAI\n",
    "openai = OpenAI(proxy_client=proxy_client)\n",
    "result = openai.chat.completions.create(\n",
    "    deployment_id=deployment_id,\n",
    "    model=model,\n",
    "    response_format=response_format,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(\"Option 1: Proxy with OpenAI-like interface\\n\", result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed21e19",
   "metadata": {},
   "source": [
    "##### 5.5 Sample#5: Citizen Reporting App with Option 2-Langchain-compatible Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48150c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Proxy with Langchain-like interface\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage\n",
    "human_msg = [\n",
    "                {\"type\": \"text\", \"text\": user_msg},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url\n",
    "                    },\n",
    "                },\n",
    "            ]\n",
    "messages = [HumanMessage(content=human_msg)]\n",
    "llm = ChatOpenAI(\n",
    "    proxy_client=proxy_client,\n",
    "    deployment_id=deployment_id,\n",
    "    model_name=model\n",
    ").bind(\n",
    " response_format=response_format\n",
    ")\n",
    "\n",
    "completion = llm.invoke(messages)\n",
    "print(\"Option 2: Proxy with Langchain-like interface\\n\", completion.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea2ad7d",
   "metadata": {},
   "source": [
    "##### 5.6 Sample#5: Citizen Reporting Use Case with Option 3-Langchain-compatible Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5920279f",
   "metadata": {},
   "source": [
    "Prepare the schema of entities about out of social medial post in citizen reporting app.<br/>\n",
    "Output example:<br/>\n",
    "```json\n",
    "{\n",
    "    \"address\": \"Oakwood Road\",\n",
    "    \"category\": \"PUBLIC CLEANLINESS\",\n",
    "    \"description\": \"The public area on Oakwood Road in Sagenai is in a disgraceful state with piles of rubbish and litter scattered everywhere. The author is frustrated with the local authorities for not maintaining cleanliness despite the taxes they pay. They hope for immediate action.\",\n",
    "    \"location\": \"51.57470453612761,0.003792117010085437\",\n",
    "    \"priority\": \"3-Medium\",\n",
    "    \"sentiment\": \"NEGATIVE\",\n",
    "    \"summary\": \"Dirty public area on Oakwood Road\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63796de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "        \n",
    "category = '''Identify if the social media reports a situation related to one of the following categories: \n",
    "            1. PUBLIC CLEANLINESS: Dirty public areas, overflowing dustbins and littering. Bulky waste in common areas.  \n",
    "            2. ROADS & FOOTPATHS: Including covered linkways, signboards & streetlights. E.g. Pot holes, huge cracks, etc.\n",
    "            3. FACILITY & PARK MAINTENANCE: Fallen trees, overgrown grass, and maintenance of park lighting and facilities.\n",
    "            4. PESTS: Sighting of bees and hornets, potential mosquito breeding sites, and more.\n",
    "            5. DRAINS & SEWERS: Choked, overflowing, or damaged drains, bad sewage smells, flooding.   \n",
    "            Output the category name. If none of the categories fits, or in doubt, return OTHER - PLEASE CHECK.  \n",
    "            '''\n",
    "\n",
    "            \n",
    "priority = '''Identify the priority to be given to the reported issues:\n",
    "            4-Low : the issue does not pose any problem with public safety and does not necessarily need to be handled urgently. \n",
    "            3-Medium : the issue does not cause any immediate danger, but it has significant and negative impact on the daily life of people in the neighborhood.\n",
    "            2-High : the issue needs to be resolved quickly because it can potentially cause dangerous situations or disruptions. \n",
    "            1-Very High : the issue needs to be handled as soon as possible, as it is a matter of public safety. \n",
    "            Return the priority level. If in doubt, return 3-Medium '''\n",
    "            \n",
    "        \n",
    "sentiment ='''Extract the sentiment of the post: \n",
    "            1. NEUTRAL: if the issue is reported politely\n",
    "            2. NEGATIVE: if the post shows irritation, impatience, annoyance\n",
    "            3. VERY NEGATIVE: the post expresses rage, hatred\n",
    "            '''\n",
    "\n",
    "address = ResponseSchema(name=\"address\",\n",
    "            description=\"Extract the address where the issue has been noticed. Return the street only and omit the town or country. For example: Oakwood Road.\")\n",
    "category = ResponseSchema(name=\"category\",\n",
    "            description=category)\n",
    "description = ResponseSchema(name=\"description\",\n",
    "            description=\"Summarize the issue that is being reported in not more that 300 characters and a neutral tone.\")\n",
    "location = ResponseSchema(name=\"location\",\n",
    "            description=\"Extract the coordinates where the issue has been notices. The format should be: (51.57470453612761,0.003792117010085437).\")\n",
    "priority = ResponseSchema(name=\"priority\",\n",
    "            description=priority)\n",
    "sentiment = ResponseSchema(name=\"sentiment\",\n",
    "            description=sentiment)\n",
    "summary = ResponseSchema(name=\"summary\",\n",
    "            description=\"Summarize the issue that is being reported in 40 characters and a neutral tone.\")\n",
    "        \n",
    "response_schemas = [\n",
    "            address,\n",
    "            category,\n",
    "            description,\n",
    "            location,\n",
    "            priority,\n",
    "            sentiment,\n",
    "            summary\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ffb21d",
   "metadata": {},
   "source": [
    "Helper function to convert the social media post into string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1624d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_to_str(input_message):\n",
    "    #message = f\"redditPostId: {input_message[\"id\"]}, author: {input_message[\"author\"]}, title: {input_message[\"title\"]}, message: {input_message[\"longText\"]}, postingDate: {input_message[\"postingDate\"]}\"\n",
    "    message = \"redditPostId: \" + input_message[\"id\"]+\\\n",
    "            \", author: \"+input_message[\"author\"]+\", title: \"+input_message[\"title\"]+\\\n",
    "            \", message: \"+input_message[\"longText\"]+\", postingDate: \"+input_message[\"postingDate\"]\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77abe76",
   "metadata": {},
   "source": [
    "Prepare the final prompt to extract the entities from the social medial post about public facility issue through citizen reporting app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = '''Extract information from the following social media post: \n",
    "            {post}\n",
    "            {format_instructions}\n",
    "            '''\n",
    "        \n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)\n",
    "        \n",
    "prompt_template = ChatPromptTemplate.from_template(template=template_string)\n",
    "input_message = {\n",
    "        \"id\": \"198qqqm\",\n",
    "        \"author\": \"jacobtan89\",\n",
    "        \"title\": \"Dirty public area\",\n",
    "        \"longText\": \"The public area on Oakwood Road in Sagenai is in a disgraceful state with piles of rubbish and litter scattered everywhere. The author is frustrated with the local authorities for not maintaining cleanliness despite the taxes they pay. They hope for immediate action. #CleanUpYourAct #OakwoodRoadNightmare #DisgustingNeighborhood Coordinates:(51.57470453612761,0.003792117010085437)\",\n",
    "        \"postingDate\": \"2024-01-17T07:13:48.000Z\"\n",
    "    }\n",
    "\n",
    "message = post_to_str(input_message)\n",
    "complete_prompt = prompt_template.format_messages(\n",
    "            post = message,\n",
    "            format_instructions = format_instructions\n",
    ")\n",
    "\n",
    "print(complete_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90445431",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    proxy_client=proxy_client,\n",
    "    deployment_id=deployment_id,\n",
    "    model_name=model,\n",
    "    temperature=0.5,\n",
    "    max_tokens=400,\n",
    "    # model_kwargs={\n",
    "    #     \"frequency_penalty\": -2, \"presence_penalty\": -1\n",
    "    # }\n",
    ")\n",
    "\n",
    "#llm_chain = complete_prompt | llm\n",
    "completion = llm.invoke(complete_prompt)\n",
    "\n",
    "print(\"Option 3: Proxy with Langchain-like interface, together with Langchain components\\n\",completion.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
